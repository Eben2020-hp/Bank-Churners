{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Education_Level_Doctorate</th>\n",
       "      <th>Education_Level_Graduate</th>\n",
       "      <th>Education_Level_High School</th>\n",
       "      <th>Education_Level_Post-Graduate</th>\n",
       "      <th>Education_Level_Uneducated</th>\n",
       "      <th>...</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.340190</td>\n",
       "      <td>0.308701</td>\n",
       "      <td>0.345116</td>\n",
       "      <td>0.035273</td>\n",
       "      <td>0.248062</td>\n",
       "      <td>0.061061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.206112</td>\n",
       "      <td>0.343266</td>\n",
       "      <td>0.214093</td>\n",
       "      <td>0.043452</td>\n",
       "      <td>0.178295</td>\n",
       "      <td>0.105105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098948</td>\n",
       "      <td>0.076611</td>\n",
       "      <td>0.077519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.056676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022977</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>0.077519</td>\n",
       "      <td>0.760761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.099091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136557</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Dependent_count  Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0       1                3                         5                       1   \n",
       "1       0                5                         6                       1   \n",
       "2       1                3                         4                       1   \n",
       "3       0                4                         3                       4   \n",
       "4       1                3                         5                       1   \n",
       "\n",
       "   Contacts_Count_12_mon  Education_Level_Doctorate  Education_Level_Graduate  \\\n",
       "0                      3                          0                         0   \n",
       "1                      2                          0                         1   \n",
       "2                      0                          0                         1   \n",
       "3                      1                          0                         0   \n",
       "4                      0                          0                         0   \n",
       "\n",
       "   Education_Level_High School  Education_Level_Post-Graduate  \\\n",
       "0                            1                              0   \n",
       "1                            0                              0   \n",
       "2                            0                              0   \n",
       "3                            1                              0   \n",
       "4                            0                              0   \n",
       "\n",
       "   Education_Level_Uneducated  ...  Card_Category_Silver  Customer_Age  \\\n",
       "0                           0  ...                     0      0.500000   \n",
       "1                           0  ...                     0      0.605263   \n",
       "2                           0  ...                     0      0.657895   \n",
       "3                           0  ...                     0      0.368421   \n",
       "4                           1  ...                     0      0.368421   \n",
       "\n",
       "   Months_on_book  Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "0        0.604651      0.340190             0.308701         0.345116   \n",
       "1        0.720930      0.206112             0.343266         0.214093   \n",
       "2        0.534884      0.059850             0.000000         0.098948   \n",
       "3        0.488372      0.056676             1.000000         0.022977   \n",
       "4        0.186047      0.099091             0.000000         0.136557   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Avg_Utilization_Ratio  Attrition_Flag  \n",
       "0         0.035273        0.248062               0.061061               1  \n",
       "1         0.043452        0.178295               0.105105               1  \n",
       "2         0.076611        0.077519               0.000000               1  \n",
       "3         0.036775        0.077519               0.760761               1  \n",
       "4         0.017025        0.139535               0.000000               1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('onehot.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data has 10016 rows and 28 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Data has {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Attrition_Flag'], axis=1)\n",
    "y = df['Attrition_Flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8012 2004\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({1: 6724, 0: 1288})\n",
      "The number of classes after fit Counter({1: 8365, 0: 6265})\n"
     ]
    }
   ],
   "source": [
    "os= SMOTETomek(0.75)\n",
    "Xtrain_bal, ytrain_bal = os.fit_resample(X, y)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(ytrain_bal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    8365\n",
      "0    6265\n",
      "Name: Attrition_Flag, dtype: int64\n",
      "\n",
      "1    1676\n",
      "0     328\n",
      "Name: Attrition_Flag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### CHECK % FOR TRAIN ANS TEST CLASSES\n",
    "print(ytrain_bal.value_counts())\n",
    "print()\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithms\n",
    "From here, we will be running the following algorithms.\n",
    "\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- Naive Bayes\n",
    "- Stochastic Gradient Decent\n",
    "- Linear SVC\n",
    "- Decision Tree\n",
    "- Gradient Boosted Trees\n",
    "- Random Forest\n",
    "\n",
    "In any model building, we mainly focus on 3 main steps:\n",
    "\n",
    "1. Fitting the model and finding the accuracy (accuracy score) of the fitted model.\n",
    "2. Perform K-Fold Cross Validation (K needs to be specified).\n",
    "3. Find the accuracy of the Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Imports\n",
    "import math,time,random,datetime\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our simplicity let us create a function that we can call for each model.\n",
    "def ML_algo(algo, X_train, y_train, cv):\n",
    "    \n",
    "    ## Step 1:\n",
    "    model = algo.fit(X_train, y_train)                          # Creating the model. We will fit the algorithm to the training data.\n",
    "    accuracy = round(model.score(X_train, y_train)*100, 2)\n",
    "\n",
    "    ## Step 2:  --> This code performs Cross Validation automatically.\n",
    "    train_pred = model_selection.cross_val_predict(algo, X_train, y_train, cv= cv, n_jobs= -1)\n",
    "\n",
    "    \n",
    "    ## Step 3:  --> Cross Validation accuracy metric.\n",
    "    accuracy_cv = round(metrics.accuracy_score(y_train, train_pred)*100, 2)\n",
    "\n",
    "    ## Step 4:  --> Confusion Matrix\n",
    "    cm = confusion_matrix(y_train, train_pred)\n",
    "    \n",
    "    return train_pred, accuracy, accuracy_cv, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "start_time = time.time()\n",
    "log_train_pred, log_acc, log_acc_cv, log_cm= ML_algo(LogisticRegression(), Xtrain_bal, ytrain_bal, 10)\n",
    "\n",
    "log_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the model is:  85.78\n",
      "Accuracy of 10-Fold CV is:  81.77\n",
      "Running time is:  0:00:11.102158\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5200 1065]\n",
      " [1602 6763]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('Accuracy of the model is: ', log_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', log_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= log_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(log_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  89.64\n",
      "Accuracy of 10-Fold CV is:  81.33\n",
      "Running time is:  0:00:19.620282\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5874  391]\n",
      " [2341 6024]]\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbours\n",
    "start_time = time.time()\n",
    "knn_train_pred, knn_acc, knn_acc_cv, knn_cm = ML_algo(KNeighborsClassifier(), Xtrain_bal, ytrain_bal, 10)\n",
    "\n",
    "knn_time = (time.time()- start_time)\n",
    "\n",
    "print('Accuracy of the model is: ', knn_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', knn_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= knn_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(knn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  73.49\n",
      "Accuracy of 10-Fold CV is:  70.2\n",
      "Running time is:  0:00:00.365621\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5350  915]\n",
      " [3445 4920]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "start_time = time.time()\n",
    "gnb_train_pred, gnb_acc, gnb_acc_cv, gnb_cm = ML_algo(GaussianNB(), Xtrain_bal, ytrain_bal, 10)\n",
    "\n",
    "gnb_time = (time.time()- start_time)\n",
    "\n",
    "print('Accuracy of the model is: ', gnb_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', gnb_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= gnb_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(gnb_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 4: Linear Support Vector Machines (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "start_time = time.time()\n",
    "svm_train_pred, svm_acc, svm_acc_cv, svm_cm = ML_algo(LinearSVC(), Xtrain_bal, ytrain_bal, 10)\n",
    "\n",
    "svm_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the model is:  85.76\n",
      "Accuracy of 10-Fold CV is:  80.96\n",
      "Running time is:  0:00:13.538316\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5239 1026]\n",
      " [1760 6605]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('Accuracy of the model is: ', svm_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', svm_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= svm_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(svm_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 5: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  85.95\n",
      "Accuracy of 10-Fold CV is:  81.59\n",
      "Running time is:  0:00:01.233890\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5052 1213]\n",
      " [1480 6885]]\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "start_time = time.time()\n",
    "sgd_train_pred, sgd_acc, sgd_acc_cv, sgd_cm = ML_algo(SGDClassifier(), Xtrain_bal, ytrain_bal, 10)\n",
    "\n",
    "sgd_time = (time.time()- start_time)\n",
    "\n",
    "print('Accuracy of the model is: ', sgd_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', sgd_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= sgd_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(sgd_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 6: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  100.0\n",
      "Accuracy of 10-Fold CV is:  89.38\n",
      "Running time is:  0:00:01.095675\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5735  530]\n",
      " [1024 7341]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "start_time = time.time()\n",
    "dtc_train_pred, dtc_acc, dtc_acc_cv, dtc_cm = ML_algo(DecisionTreeClassifier(), Xtrain_bal, ytrain_bal, 10)\n",
    "\n",
    "dtc_time = (time.time()- start_time)\n",
    "\n",
    "print('Accuracy of the model is: ', dtc_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', dtc_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= dtc_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(dtc_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 7: Gradient Boost Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  94.88\n",
      "Accuracy of 10-Fold CV is:  91.78\n",
      "Running time is:  0:00:20.455931\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5832  433]\n",
      " [ 769 7596]]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost Trees\n",
    "start_time = time.time()\n",
    "gbt_train_pred, gbt_acc, gbt_acc_cv, gbt_cm = ML_algo(GradientBoostingClassifier(), Xtrain_bal, ytrain_bal, 10)\n",
    "\n",
    "gbt_time = (time.time()- start_time)\n",
    "\n",
    "print('Accuracy of the model is: ', gbt_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', gbt_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= gbt_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(gbt_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 8: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "start_time = time.time()\n",
    "algorithm1 = RandomForestClassifier()\n",
    "\n",
    "## Step 1:\n",
    "modelRF = algorithm1.fit(Xtrain_bal, ytrain_bal)      # Creating the model. We will fit the algorithm to the training data.\n",
    "rf_acc = round(modelRF.score(Xtrain_bal, ytrain_bal)*100, 2)\n",
    "\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\n",
    "rf_train_pred = model_selection.cross_val_predict(algorithm1, Xtrain_bal, ytrain_bal, cv= 10, n_jobs= -1)\n",
    "\n",
    "## Step 3:  --> Cross Validation accuracy metric.\n",
    "rf_acc_cv = round(metrics.accuracy_score(ytrain_bal, rf_train_pred)*100, 2)\n",
    "\n",
    "rf_cm = confusion_matrix(ytrain_bal, rf_train_pred)\n",
    "\n",
    "rf_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  100.0\n",
      "Accuracy of 10-Fold CV is:  93.42\n",
      "Running time is:  0:00:12.756637\n",
      "\n",
      "Confusion Matrix: \n",
      "[[6002  263]\n",
      " [ 700 7665]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is: ', rf_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', rf_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= rf_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(rf_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 9: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:01:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/eben.emmanuel/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:02:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "algorithm2 = XGBClassifier()\n",
    "\n",
    "## Step 1:\n",
    "modelXGB = algorithm2.fit(Xtrain_bal, ytrain_bal)      # Creating the model. We will fit the algorithm to the training data.\n",
    "xgb_acc = round(modelXGB.score(Xtrain_bal, ytrain_bal)*100, 2)\n",
    "\n",
    "## Step 2:  --> This code performs Cross Validation automatically.\n",
    "xgb_train_pred = model_selection.cross_val_predict(algorithm2, Xtrain_bal, ytrain_bal, cv= 10, n_jobs= -1)\n",
    "\n",
    "## Step 3:  --> Cross Validation accuracy metric.\n",
    "xgb_acc_cv = round(metrics.accuracy_score(ytrain_bal, xgb_train_pred)*100, 2)\n",
    "\n",
    "xgb_cm = confusion_matrix(ytrain_bal, xgb_train_pred)\n",
    "\n",
    "xgb_time = (time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  99.82\n",
      "Accuracy of 10-Fold CV is:  94.33\n",
      "Running time is:  0:00:26.423745\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5981  284]\n",
      " [ 545 7820]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model is: ', xgb_acc)\n",
    "print('Accuracy of 10-Fold CV is: ', xgb_acc_cv)\n",
    "print('Running time is: ', datetime.timedelta(seconds= xgb_time))\n",
    "print()\n",
    "print('Confusion Matrix: ')\n",
    "print(xgb_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results\n",
    "Now let's see which model has the best cross-validation accuracy.\n",
    "\n",
    "- **NOTE: We care more about the accuracy of cross validation, as the metrics we get from the model can randomly score higher than usual.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Cross-Validation Accuracy Scores-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>94.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>93.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost Trees</td>\n",
       "      <td>91.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>89.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>81.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>81.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbours</td>\n",
       "      <td>81.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Support Vector Machines (SVC)</td>\n",
       "      <td>80.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>70.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  Score\n",
       "8                               XGBoost  94.33\n",
       "7                         Random Forest  93.42\n",
       "6                  Gradient Boost Trees  91.78\n",
       "5              Decision Tree Classifier  89.38\n",
       "0                   Logistic Regression  81.77\n",
       "4           Stochastic Gradient Descent  81.59\n",
       "1                  K-Nearest Neighbours  81.33\n",
       "3  Linear Support Vector Machines (SVC)  80.96\n",
       "2                  Gaussian Naive Bayes  70.20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_models = pd.DataFrame({'Model':[' Logistic Regression', 'K-Nearest Neighbours', 'Gaussian Naive Bayes', \n",
    "                                'Linear Support Vector Machines (SVC)', 'Stochastic Gradient Descent', \n",
    "                                'Decision Tree Classifier', 'Gradient Boost Trees', 'Random Forest', 'XGBoost'],\n",
    "                      'Score':[log_acc_cv, knn_acc_cv, gnb_acc_cv, svm_acc_cv, sgd_acc_cv, dtc_acc_cv, gbt_acc_cv, rf_acc_cv, xgb_acc_cv]})\n",
    "\n",
    "print('-----Cross-Validation Accuracy Scores-----')\n",
    "cv_models.nlargest(9,'Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the Test dataset\n",
    "\n",
    "Let's use the model with the highest cross-validation accuracy score to make a prediction on the test dataset.\n",
    "\n",
    "We want to make predictions on the same columnns our model is trained on.\n",
    "\n",
    "So we have to select the subset of right columns of the test dateframe, encode them and make a prediciton with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is:  99.6\n",
      "\n",
      "Precision of the model is:  99.88\n",
      "Recall of the model is:  99.64\n",
      "F1 Score of the model is:  99.76\n"
     ]
    }
   ],
   "source": [
    "## Prediction on Validation Data\n",
    "y_pred = modelXGB.predict(X_test)\n",
    "\n",
    "print('Accuracy of the model is: ', round(metrics.accuracy_score(y_test, y_pred)*100,2))\n",
    "print()\n",
    "print('Precision of the model is: ', round(metrics.precision_score(y_test, y_pred)*100,2))\n",
    "print('Recall of the model is: ', round(metrics.recall_score(y_test, y_pred)*100,2))\n",
    "print('F1 Score of the model is: ', round(metrics.f1_score(y_test, y_pred)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 326,    2],\n",
       "       [   6, 1670]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d26db0583b8d86dff58934c3f0443a821e6254989a7bf836030ed14e58471b87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
